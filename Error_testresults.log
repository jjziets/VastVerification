1719220368: Error logs for machine_id. Tested  158 instances
25075:11250979 No Direct Ports found get_status_msg = running
14954:11250970 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
24394:11250972 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
25069:11251067 No Direct Ports found get_status_msg = running
14957:11250975 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
22030:11250994  instance exited
24191:11251040 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 111] Connection refused>
21579:11251145 No Direct Ports found get_status_msg = running
22265:11251134 ERROR 1: System requirements test failed. System total memory is less than the sum of all the GPUs VRAM.
 
23336:11251142 ERROR 1: System requirements test failed. System total memory is less than the sum of all the GPUs VRAM.
 
24835:11251204 No Direct Ports found get_status_msg = running
21223:11251131 11251131  Error response from daemon: unknown or invalid runtime name: nvidia
24830:11251199 11251199  Error response from daemon: Unknown runtime specified nvidia
24830:11251196 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
22862:11251304 No Direct Ports found get_status_msg = running
21674:11251203 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
15900:11251200 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 111] Connection refused>
24083:11251302 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 111] Connection refused>
24585:11251342 No Direct Ports found get_status_msg = running
23522:11251301 No Direct Ports found get_status_msg = running
24337:11251022 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
24836:11251298 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
20827:11251300 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
24159:11251399 No Direct Ports found get_status_msg = running
23322:11251016 No Direct Ports found get_status_msg = running
25083:11251337 11251337  Error response from daemon: unknown or invalid runtime name: nvidia
20732:11251397 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 104] Connection reset by peer>
24039:11251482 No Direct Ports found get_status_msg = running
24357:11251384 ERROR 1: System requirements test failed. System total memory is less than the sum of all the GPUs VRAM.
 
25001:11251391 ERROR 1: System requirements test failed. System total memory is less than the sum of all the GPUs VRAM.
 
20363:11251473 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 111] Connection refused>
20363:11251474  Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running hook #1: error running hook: exit status 1, stdout: , stderr: Auto-detected mode as 'legacy'
nvidia-container-cli: device error: 2: unknown device: unknown
Error: failed to start containers: C.11251474
21191:11251481 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 111] Connection refused>
17267:11251392 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
23972:11251519 No Direct Ports found get_status_msg = running
24791:11251513 ERROR 1: System requirements test failed.  Traceback (most recent call last):
  File "/pytorch-benchmark-volta/systemreqtest.py", line 55, in <module>
    sys.exit(main())
  File "/pytorch-benchmark-volta/systemreqtest.py", line 15, in main
    first_gpu_model = torch.cuda.get_device_name(0)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 432, in get_device_name
    return get_device_properties(device).name
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 462, in get_device_properties
    _lazy_init()  # will define _get_device_properties
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 311, in _lazy_init
    torch._C._cuda_init()
RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW
20161:11251478 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
24999:11251536 No Direct Ports found get_status_msg = running
24999:11250962 Time exceeded get_status_msg = loading
17791:11251517 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
17209:11251507 No Direct Ports found get_status_msg = running
24706:11251512 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 111] Connection refused>
14901:11251518 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
25027:11251670 No Direct Ports found get_status_msg = running
21320:11251650 No Direct Ports found get_status_msg = running
17046:11251657 11251657  Error response from daemon: unknown or invalid runtime name: nvidia
24996:11251797 No Direct Ports found get_status_msg = running
24996:11251531 11251531  Error response from daemon: unknown or invalid runtime name: nvidia
24661:11251532 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
19602:11251829 No Direct Ports found get_status_msg = running
25029:11251780 ERROR 2: Test All GPU ResNet50 failed. Benchmarking ResNet50 on batch size 512 with 10 GPUs
 Traceback (most recent call last):
  File "/pytorch-benchmark-volta/testAllGpusResNet50.py", line 91, in <module>
    main()
  File "/pytorch-benchmark-volta/testAllGpusResNet50.py", line 84, in main
    raise e
  File "/pytorch-benchmark-volta/testAllGpusResNet50.py", line 64, in main
    model(img)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py", line 176, in forward
    inputs, module_kwargs = self.scatter(inputs, kwargs, self.device_ids)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py", line 198, in scatter
    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/scatter_gather.py", line 77, in scatter_kwargs
    scattered_inputs = scatter(inputs, target_gpus, dim) if inputs else []
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/scatter_gather.py", line 64, in scatter
    res = scatter_map(inputs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/scatter_gather.py", line 51, in scatter_map
    return list(zip(*map(scatter_map, obj)))
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/scatter_gather.py", line 47, in scatter_map
    return Scatter.apply(target_gpus, None, dim, obj)
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py", line 574, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py", line 96, in forward
    outputs = comm.scatter(input, target_gpus, chunk_sizes, ctx.dim, streams)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/comm.py", line 188, in scatter
    return tuple(torch._C._scatter(tensor, devices, chunk_sizes, dim, streams))
RuntimeError: CUDA error: peer mapping resources exhausted
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
25029:11251790  went offline
23772:11251823 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 113] No route to host>
16417:11251825 ERROR 1: System requirements test failed. System total memory is less than the sum of all the GPUs VRAM.
 
21647:11251844 No Direct Ports found get_status_msg = running
15516:11251795 ERROR 1: System requirements test failed. System total memory is less than the sum of all the GPUs VRAM.
 
23999:11251841 Unable to find image 'jjziets/vasttest_latest/jupyter:latest' locally
Error response from daemon: pull access denied for jjziets/vasttest_latest/jupyter, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
17220:11251834 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 110] Connection timed out>
24727:11251861 No Direct Ports found get_status_msg = running
24727:11251335 Time exceeded get_status_msg = loading
24727:11251341 Time exceeded get_status_msg = loading
14477:11251822 No Direct Ports found get_status_msg = running
24753:11251842 ERROR: Failed to connect or retrieve data: <urlopen error [Errno 113] No route to host>
